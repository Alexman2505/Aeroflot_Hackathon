{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK7X8Bpwa31e"
      },
      "outputs": [],
      "source": [
        "!pip install thop\n",
        "!pip install onnxruntime\n",
        "#!pip install onnxruntime-gpu\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import psutil\n",
        "import shutil\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime as ort\n",
        "from google.colab import drive\n",
        "from copy import deepcopy\n",
        "from ultralytics import YOLO\n",
        "from thop import profile\n"
      ],
      "metadata": {
        "id": "m4WQeMXsa56N"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "!unzip -q /content/gdrive/MyDrive/data.zip"
      ],
      "metadata": {
        "id": "duZHxfPldUoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c197658-dd8a-4b6a-8114-0156a35caac6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory_usage():\n",
        "    \"\"\"Получение текущего потребления памяти\"\"\"\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / 1024 / 1024  # в МБ\n",
        "\n",
        "def run_inference_pytorch(model, images, device='cpu'):\n",
        "    \"\"\"Запуск инференса на PyTorch модели\"\"\"\n",
        "    model.model.to(device)\n",
        "    times = []\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "        start_time = time.time()\n",
        "\n",
        "        results = model(img_path, verbose=False)\n",
        "\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "\n",
        "    return times\n",
        "\n",
        "def run_inference_onnx(model_path, images, device='cpu'):\n",
        "    \"\"\"Запуск инференса на ONNX модели\"\"\"\n",
        "    providers = ['CPUExecutionProvider'] if device == 'cpu' else ['CUDAExecutionProvider']\n",
        "    session = ort.InferenceSession(model_path, providers=providers)\n",
        "    times = []\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "\n",
        "        # Подготовка входных данных для ONNX\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (640, 640))\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = np.transpose(img, (2, 0, 1))\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        input_name = session.get_inputs()[0].name\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        outputs = session.run(None, {input_name: img})\n",
        "\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "\n",
        "    return times\n"
      ],
      "metadata": {
        "id": "_yVviVXhlFgn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_colab(model, images, output_dir):\n",
        "    \"\"\"Сохранение изображений с bounding boxes в Google Colab\"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "        results = model(img_path, verbose=False)\n",
        "\n",
        "        # Сохранение результата\n",
        "        for r in results:\n",
        "            im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "            im = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n",
        "            output_path = os.path.join(output_dir, img_name)\n",
        "            cv2.imwrite(output_path, im_array)\n",
        "\n",
        "    print(f\"Аннотированные изображения сохранены в {output_dir}\")\n",
        "\n",
        "def save_to_drive(colab_output_folder, drive_output_folder):\n",
        "    \"\"\"Сохранение изображений с bounding boxes в Google Drive\"\"\"\n",
        "\n",
        "    os.makedirs(drive_output_folder, exist_ok=True)\n",
        "\n",
        "    files_to_copy = [f for f in os.listdir(colab_output_folder)]\n",
        "\n",
        "    for file_name in files_to_copy:\n",
        "        file_path = os.path.join(colab_output_folder, file_name)\n",
        "        if os.path.exists(file_path):\n",
        "            shutil.copy(file_path, drive_output_folder)\n",
        "\n",
        "    print(f\"Аннотированные изображения сохранены в: {drive_output_folder}\")\n"
      ],
      "metadata": {
        "id": "BhgOi0LdjdOe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пути\n",
        "\n",
        "test_folder = './test'\n",
        "colab_output_folder = './test_results'\n",
        "drive_output_folder = '/content/gdrive/MyDrive/test_results'"
      ],
      "metadata": {
        "id": "3UFOV8I97qMA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = [f for f in os.listdir(test_folder) if f.lower().endswith('.jpg')]\n",
        "test_count = len(test_images)\n",
        "\n",
        "print(f\"Количество фото в папке test: {test_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCCOGIDN7q-4",
        "outputId": "f7ddea40-66e6-49e2-a324-2c3331c0c676"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество фото в папке test: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Сохранение фото с bounding boxes"
      ],
      "metadata": {
        "id": "yb29Z5Mz57VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка моделей\n",
        "\n",
        "pytorch_model = YOLO('08_best_model.pt')\n",
        "onnx_model = '08_best_model.onnx'\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Используемое устройство: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB6H5K-P6Gy2",
        "outputId": "131cb799-567b-46ff-b935-6fdb5b62ce1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_colab(pytorch_model, test_images, colab_output_folder)\n",
        "save_to_drive(colab_output_folder, drive_output_folder)"
      ],
      "metadata": {
        "id": "pC1RuapdpdWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78422434-07cb-44ec-c662-79e19d22fee5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ━━━━━━━━━━━━ 22.2MB 73.0MB/s 0.3s\n",
            "Аннотированные изображения сохранены в ./test_results\n",
            "Аннотированные изображения сохранены в: /content/gdrive/MyDrive/test_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Измерения на CPU"
      ],
      "metadata": {
        "id": "IXN2qnWvo3-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "\n",
        "# Потребление памяти перед инференсом\n",
        "initial_memory = get_memory_usage()\n",
        "gc.collect()\n",
        "start_time = time.time()\n",
        "\n",
        "pytorch_cpu_times = run_inference_pytorch(pytorch_model, test_images, 'cpu')\n",
        "pytorch_cpu_total_time = time.time() - start_time\n",
        "\n",
        "# Потребление памяти после инференса\n",
        "final_memory = get_memory_usage()\n",
        "memory_usage = final_memory - initial_memory\n",
        "\n",
        "print(f\"PyTorch - Общее время обработки: {pytorch_cpu_total_time:.2f} сек\")\n",
        "print(f\"PyTorch - Среднее время на снимок: {np.mean(pytorch_cpu_times):.4f} сек\")\n",
        "print(f\"PyTorch - Потребление памяти: {memory_usage:.2f} МБ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDYde6Qv_bmy",
        "outputId": "2181d56a-30e5-47bf-e1ca-ae6b940e15e3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch - Общее время обработки: 50.13 сек\n",
            "PyTorch - Среднее время на снимок: 1.3924 сек\n",
            "PyTorch - Потребление памяти: -0.07 МБ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX\n",
        "\n",
        "# Потребление памяти перед инференсом\n",
        "initial_memory = get_memory_usage()\n",
        "gc.collect()\n",
        "start_time = time.time()\n",
        "onnx_cpu_times = run_inference_onnx(onnx_model, test_images, 'cpu')\n",
        "onnx_cpu_total_time = sum(onnx_cpu_times)\n",
        "\n",
        "# Потребление памяти после инференса\n",
        "final_memory = get_memory_usage()\n",
        "memory_usage = final_memory - initial_memory\n",
        "\n",
        "print(f\"ONNX - Общее время обработки: {onnx_cpu_total_time:.2f} сек\")\n",
        "print(f\"ONNX - Среднее время на снимок: {np.mean(onnx_cpu_times):.4f} сек\")\n",
        "print(f\"ONNX - Потребление памяти: {memory_usage:.2f} МБ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHNcLAOBWfc",
        "outputId": "1dd03c5e-5082-4451-fb95-e39d6f783c4c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX - Общее время обработки: 49.26 сек\n",
            "ONNX - Среднее время на снимок: 1.3684 сек\n",
            "ONNX - Потребление памяти: -4.46 МБ\n"
          ]
        }
      ]
    }
  ]
}