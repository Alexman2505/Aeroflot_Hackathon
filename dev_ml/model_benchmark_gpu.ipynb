{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK7X8Bpwa31e"
      },
      "outputs": [],
      "source": [
        "!pip install thop\n",
        "!pip install onnxruntime\n",
        "!pip install onnxruntime-gpu\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import psutil\n",
        "import shutil\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime as ort\n",
        "from google.colab import drive\n",
        "from copy import deepcopy\n",
        "from ultralytics import YOLO\n",
        "from thop import profile\n"
      ],
      "metadata": {
        "id": "m4WQeMXsa56N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129dcc13-f5b7-4863-fb10-caaa7d673753"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "!unzip -q /content/gdrive/MyDrive/data.zip"
      ],
      "metadata": {
        "id": "duZHxfPldUoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1c593a-c864-447a-8c3f-f1044252a00b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory_usage():\n",
        "    \"\"\"Получение текущего потребления памяти\"\"\"\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / 1024 / 1024  # в МБ\n",
        "\n",
        "def run_inference_pytorch(model, images, device='cpu'):\n",
        "    \"\"\"Запуск инференса на PyTorch модели\"\"\"\n",
        "    model.model.to(device)\n",
        "    times = []\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "        start_time = time.time()\n",
        "\n",
        "        results = model(img_path, verbose=False)\n",
        "\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "\n",
        "    return times\n",
        "\n",
        "def run_inference_onnx(model_path, images, device='cpu'):\n",
        "    \"\"\"Запуск инференса на ONNX модели\"\"\"\n",
        "    providers = ['CPUExecutionProvider'] if device == 'cpu' else ['CUDAExecutionProvider']\n",
        "    session = ort.InferenceSession(model_path, providers=providers)\n",
        "    times = []\n",
        "\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(test_folder, img_name)\n",
        "\n",
        "        # Подготовка входных данных для ONNX\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (640, 640))\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = np.transpose(img, (2, 0, 1))\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        input_name = session.get_inputs()[0].name\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        outputs = session.run(None, {input_name: img})\n",
        "\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "\n",
        "    return times\n"
      ],
      "metadata": {
        "id": "_yVviVXhlFgn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пути\n",
        "\n",
        "test_folder = './test'\n",
        "colab_output_folder = './test_results'\n",
        "drive_output_folder = '/content/gdrive/MyDrive/test_results'"
      ],
      "metadata": {
        "id": "3UFOV8I97qMA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = [f for f in os.listdir(test_folder) if f.lower().endswith('.jpg')]\n",
        "test_count = len(test_images)\n",
        "\n",
        "print(f\"Количество фото в папке test: {test_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCCOGIDN7q-4",
        "outputId": "b9aee3bf-67d8-487b-a0d6-6964d31c166a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество фото в папке test: 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка моделей\n",
        "\n",
        "pytorch_model = YOLO('best_model.pt')\n",
        "onnx_model = 'best_model.onnx'\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Используемое устройство: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB6H5K-P6Gy2",
        "outputId": "09eca9c8-8111-4511-b1fc-92a39c90057d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Измерения на GPU"
      ],
      "metadata": {
        "id": "IXN2qnWvo3-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "start_time = time.time()\n",
        "\n",
        "pytorch_gpu_times = run_inference_pytorch(pytorch_model, test_images, 'cuda')\n",
        "pytorch_gpu_total_time = time.time() - start_time\n",
        "\n",
        "print(f\"PyTorch - Общее время обработки: {pytorch_gpu_total_time:.2f} сек\")\n",
        "print(f\"PyTorch - Среднее время на снимок: {np.mean(pytorch_gpu_times):.4f} сек\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDYde6Qv_bmy",
        "outputId": "4887dbd9-2b9d-4b98-fcf4-479a48f0e675"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch - Общее время обработки: 23.68 сек\n",
            "PyTorch - Среднее время на снимок: 0.2893 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "start_time = time.time()\n",
        "\n",
        "onnx_gpu_times = run_inference_onnx(onnx_model, test_images, 'cuda')\n",
        "onnx_gpu_total_time = sum(onnx_gpu_times)\n",
        "\n",
        "print(f\"ONNX - Общее время обработки: {onnx_gpu_total_time:.2f} сек\")\n",
        "print(f\"ONNX - Среднее время на снимок: {np.mean(onnx_gpu_times):.4f} сек\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHNcLAOBWfc",
        "outputId": "259a2f50-cec5-4d70-de04-c0ec87f15653"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX - Общее время обработки: 3.64 сек\n",
            "ONNX - Среднее время на снимок: 0.0449 сек\n"
          ]
        }
      ]
    }
  ]
}